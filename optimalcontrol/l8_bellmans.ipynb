{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bellman's Principle\n",
    "\n",
    "Optimal control problems have an inherently sequential structure/\n",
    "\n",
    "Past control inputs only affect futures states, future control inputs cannot affect past states.\n",
    "\n",
    "Bellman's Principle (of Optimality) states the consequences of this for optimal trajectories.\n",
    "\n",
    "![bellmans](images/l8_bellman.png)\n",
    "\n",
    "Sub trajectories of optimal trajectories have to be optimal for appropriately defined sub problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming\n",
    "\n",
    "Bellman's principle suggests starting from the end of the trajectory and only working backwards.\n",
    "\n",
    "We've already seen hints of this from the Riccati equation and Pontryagin.\n",
    "\n",
    "Define an \"optimal cost-to-go\" aka \"value function\" termed $V_k(X_k)$. This encodes cost incurred starting from state $x_k$ at time $k$ if we act optimally to the end.\n",
    "\n",
    "For LQR, the terminal value function is \n",
    "\n",
    "```{admonition} TODO\n",
    "Check and fix the working below\n",
    "```\n",
    "\n",
    "$$\n",
    "V_N(x)=\\frac{1}{2} x^{\\top} Q_N x=\\frac{1}{2} x^{\\top} P_N x\n",
    "$$\n",
    "\n",
    "The working backwards\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& V_{N-1}=\\min _u \\frac{1}{2} x_{N-1}^{\\top} Q x_{n-1}+\\frac{1}{2} u^{\\top} R u + V_N\\left(A_{N-1} x_{N-1}+B_{N-1} u\\right) \\\\\n",
    "\n",
    "& \\Rightarrow \\min _{u} \\frac{1}{2} u^T R u+\\left(A x_{N-1}+B u\\right)^\\top P_N\\left(A x_{N-1}+Bu\\right) \\\\\n",
    "\n",
    "& \\Rightarrow R_u+B^{\\top} P_N\\left(A x_{N-1}+B u\\right)=0 \\qquad \\text{when} \\quad \\nabla u = 0\\\\\n",
    "\n",
    "& \\Rightarrow u_{N-1}=-\\underbrace{\\left(R_{N-1}+B_{N-1}^{\\top} P_N B_{N-1}\\right)^{-1} B_{N-1} P_N A_{N-1}}_{K_{N-1}} X_{N-1} \\\\\n",
    "&\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Plugging this back into the value function\n",
    "\n",
    "$$\n",
    "V_{N-1}(x)=\\frac{1}{2} x^{\\top} \\underbrace{\\left[  Q+K^{\\top} R K+(A-B K)^{\\top} P_N(A-B K) \\right]}_{P_{N-1} }  x\n",
    "$$\n",
    "\n",
    "```{note}\n",
    "There are many ways of writing the $P$ equations but  this is better for floating point error.\n",
    "```\n",
    "\n",
    "This is Riccati again!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming Algorithm\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& V_N(x) \\leftarrow \\mathcal{L}_N(x) \\\\\n",
    "& k=N \\\\\n",
    "& \\text{while } k>1 \\\\\n",
    "& V_{k-1}(x)=\\min _{u \\in u}\\left[\\mathcal{L ( x , u )}+V_k(f(x, u))\\right] \\\\\n",
    "& k \\leftarrow k-1 \\\\\n",
    "& \\text { end } \\\\\n",
    "&\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If we know $V_k(x)$ the optimal policy is \n",
    "\n",
    "\n",
    "\n",
    "DP equations written equivalently in terms of \"actions-value\" or \"Q\" functions\n",
    "\n",
    "\n",
    "Usually denoted $Q(x,u)$ but we will use $S(x,u)$ t avoid confusion with LQR.\n",
    "\n",
    "This form avoids the need for and explicit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse\n",
    "\n",
    "DP is sufficient for global optimum\n",
    "\n",
    "Only tractable for simple problems (LQR or low dimensional)\n",
    "\n",
    "$V(x)$ stays quadratic for LQR but becomes impossible to write analytically for even simple non-lienar problems \n",
    "\n",
    "Even if we could write it $\\min S(x,u)$ will be non-convex and possibly hard to solve.\n",
    "\n",
    "Cost of DP blows up with state dimension due to difficulty of representative $V(x)$\n",
    "\n",
    "## Then why do we care about this?\n",
    "\n",
    "Approximate DP with a function approximator for $V(x)$ or $S(x,u)$ is very powerful (basis of modern RL)\n",
    "\n",
    "DP generalizes to stochastic problems (just wrap everything in expectation operators). Pontryagin does not.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
